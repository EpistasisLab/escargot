{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ESCARGOT benchmarking</h1>\n",
    "<h2>Manually configured Escargot for the ALZKB public knowledge graph and private weaviate server</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"azuregpt35-16k\" : {\n",
    "        \"model_id\":\"gpt-35-turbo-16k\", \n",
    "        \"prompt_token_cost\": 0.001,\n",
    "        \"response_token_cost\": 0.002,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2000,\n",
    "        \"stop\": None,\n",
    "        \"api_version\": \"\",\n",
    "        \"api_base\": \"\",\n",
    "        \"api_key\": \"\",\n",
    "        \"embedding_id\":\"text-embedding-ada-002\"\n",
    "    },\n",
    "    \"memgraph\" : {\n",
    "        \"host\": \"\",\n",
    "        \"port\": 7687\n",
    "    },\n",
    "    \"weaviate\" : {\n",
    "        \"api_key\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"db\": \"\",\n",
    "        \"limit\": 200\n",
    "    }\n",
    "}\n",
    "\n",
    "from escargot import Escargot\n",
    "escargot = Escargot(config, node_types = \"BiologicalProcess, BodyPart, CellularComponent, Datatype, Disease, Drug, DrugClass, Gene, MolecularFunction, Pathway, Symptom\", relationship_types = \"\"\"CHEMICALBINDSGENE\n",
    "CHEMICALDECREASESEXPRESSION\n",
    "CHEMICALINCREASESEXPRESSION\n",
    "DRUGINCLASS\n",
    "DRUGCAUSESEFFECT\n",
    "DRUGTREATSDISEASE\n",
    "GENEPARTICIPATESINBIOLOGICALPROCESS\n",
    "GENEINPATHWAY\n",
    "GENEINTERACTSWITHGENE\n",
    "GENEHASMOLECULARFUNCTION\n",
    "GENEASSOCIATEDWITHCELLULARCOMPONENT\n",
    "GENEASSOCIATESWITHDISEASE\n",
    "SYMPTOMMANIFESTATIONOFDISEASE\n",
    "BODYPARTUNDEREXPRESSESGENE\n",
    "BODYPARTOVEREXPRESSESGENE\n",
    "DISEASELOCALIZESTOANATOMY\n",
    "DISEASEASSOCIATESWITHDISEASET\"\"\", \n",
    "model_name=\"azuregpt35-16k\")\n",
    "escargot.memgraph_client.schema = \"\"\"Node properties are the following:\n",
    "Node name: 'BiologicalProcess', Node properties: ['commonName']\n",
    "Node name: 'BodyPart', Node properties: ['commonName']\n",
    "Node name: 'CellularComponent', Node properties: ['commonName']\n",
    "Node name: 'Disease', Node properties: ['commonName']\n",
    "Node name: 'Drug', Node properties: ['commonName']\n",
    "Node name: 'DrugClass', Node properties: ['commonName']\n",
    "Node name: 'Gene', Node properties: ['commonName', 'geneSymbol', 'typeOfGene']\n",
    "Node name: 'MolecularFunction', Node properties: ['commonName']\n",
    "Node name: 'Pathway', Node properties: ['commonName']\n",
    "Node name: 'Symptom', Node properties: ['commonName']\n",
    "Relationship properties are the following:\n",
    "The relationships are the following:\n",
    "(:Drug)-[:CHEMICALBINDSGENE]-(:Gene)\n",
    "(:Drug)-[:CHEMICALDECREASESEXPRESSION]-(:Gene)\n",
    "(:Drug)-[:CHEMICALINCREASESEXPRESSION]-(:Gene)\n",
    "(:Drug)-[:DRUGINCLASS]-(:DrugClass)\n",
    "(:Drug)-[:DRUGCAUSESEFFECT]-(:Disease)\n",
    "(:Drug)-[:DRUGTREATSDISEASE]-(:Disease)\n",
    "(:Gene)-[:GENEPARTICIPATESINBIOLOGICALPROCESS]-(:BiologicalProcess)\n",
    "(:Gene)-[:GENEINPATHWAY]-(:Pathway)\n",
    "(:Gene)-[:GENEINTERACTSWITHGENE]-(:Gene)\n",
    "(:Gene)-[:GENEHASMOLECULARFUNCTION]-(:MolecularFunction)\n",
    "(:Gene)-[:GENEASSOCIATEDWITHCELLULARCOMPONENT]-(:CellularComponent)\n",
    "(:Gene)-[:GENEASSOCIATESWITHDISEASE]-(:Disease)\n",
    "(:Symptom)-[:SYMPTOMMANIFESTATIONOFDISEASE]-(:Disease)\n",
    "(:BodyPart)-[:BODYPARTUNDEREXPRESSESGENE]-(:Gene)\n",
    "(:BodyPart)-[:BODYPARTOVEREXPRESSESGENE]-(:Gene)\n",
    "(:Disease)-[:DISEASELOCALIZESTOANATOMY]-(:BodyPart)\n",
    "(:Disease)-[:DISEASEASSOCIATESWITHDISEASET]-(:Disease)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dill\n",
    "json_files =  ['MCQ_1hop.json', 'MCQ_2hop.json', 'OpenEnded_1hop.json', 'OpenEnded_2hop.json', 'True_or_False_1hop.json', 'True_or_False_2hop.json']\n",
    "responses = {}\n",
    "for json_file in json_files:\n",
    "    print(json_file)\n",
    "    with open(\"../dataset/\"+json_file) as f:\n",
    "        data = json.load(f)\n",
    "    responses[json_file] = {}\n",
    "    for question in data:\n",
    "        response = ''\n",
    "        tries = 0\n",
    "        while response == '' and tries < 3:\n",
    "            escargot.memgraph_client.cache = {}\n",
    "            try:\n",
    "                response = escargot.ask(question['question'], answer_type= \"array\",debug_level = 0)\n",
    "            except Exception as e:\n",
    "                response = ''\n",
    "            tries += 1\n",
    "        \n",
    "        print('question:', question['question'], 'answer:', question['answer'], 'response:', response)\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "        responses[json_file][question['question']] = str(response)\n",
    "dill.dump(responses, open('Escargot_esponses.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Base GPT3.5</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_GENERATION_TEMPLATE = \"\"\"\n",
    "Answer the following question and return only the answer. If it's multiple choice, return the answer in the format \"1\", \"2\", \"3\", \"4\", etc. If it's a free text answer, return the answer as a string.\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dill\n",
    "json_files =  ['MCQ_1hop.json', 'MCQ_2hop.json', 'OpenEnded_1hop.json', 'OpenEnded_2hop.json', 'True_or_False_1hop.json', 'True_or_False_2hop.json']\n",
    "responses = {}\n",
    "for json_file in json_files:\n",
    "    print(json_file)\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    responses[json_file] = {}\n",
    "    for question in data:\n",
    "        response = ''\n",
    "        formatted_question = BASE_GENERATION_TEMPLATE.format(question = question['question'])\n",
    "        try:\n",
    "            response = escargot.quick_chat(formatted_question)\n",
    "            # Remove \"Answer:\" from the response\n",
    "            if response.startswith(\"Answer:\"):\n",
    "                response= response[8:].strip()\n",
    "            \n",
    "            #remove ```cypher from the response\n",
    "            response = response.replace(\"```cypher\", \"\")\n",
    "\n",
    "            #remove ``` from anywhere in the response\n",
    "            response = response.replace(\"```\", \"\")\n",
    "\n",
    "            #remove \\n from the response\n",
    "            response = response.replace(\"\\n\", \"\")\n",
    "            \n",
    "            # print(\"Memgraph request:\",response)\n",
    "            print(\"question:\",question['question'])\n",
    "            print(\"request:\",response)\n",
    "        except Exception as e:\n",
    "            # print(\"Memgraph request failed\",e)\n",
    "            response = ''\n",
    "        \n",
    "        responses[json_file][question['question']] = str(response)\n",
    "        # break\n",
    "    # break\n",
    "dill.dump(responses, open('results/Base_responses.pkl', 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>RAG</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_RAG_TEST = {\n",
    "    \"azuregpt35-16k\" : {\n",
    "        \"model_id\":\"gpt-35-turbo-16k\", \n",
    "        \"prompt_token_cost\": 0.001,\n",
    "        \"response_token_cost\": 0.002,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"stop\": None,\n",
    "        \"api_version\": \"2023-07-01-preview\",\n",
    "        \"api_base\": \"\",\n",
    "        \"api_key\": \"\",\n",
    "        \"embedding_id\":\"text-embedding-ada-002\"\n",
    "    },\n",
    "    # \"memgraph\" : {\n",
    "    #     \"host\": \"\",\n",
    "    #     \"port\": 7687\n",
    "    # },\n",
    "    \"weaviate\" : {\n",
    "\n",
    "        \"api_key\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"db\": \"\",\n",
    "        \"limit\": 200,\n",
    "\n",
    "        \"max_tokens_weaviate\": 10000,\n",
    "        \"quantile_weaviate\": 0.1,\n",
    "        \"max_distance_weaviate\": 0.25,\n",
    "        \"show_distances_weaviate\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dill\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def set_paths(base_dir, *subdirs):\n",
    "    return [os.path.join(base_dir, subdir) for subdir in subdirs]\n",
    "\n",
    "notebook_dir = os.getcwd()  # Get the current working directory\n",
    "sys.path.append(os.path.join(notebook_dir, \"../escargot/benchmarking/notebooks\"))\n",
    "\n",
    "dataset_dir, results_dir = set_paths(notebook_dir, \"../dataset\", \"../results\")\n",
    "\n",
    "\n",
    "dataset_dir = os.path.abspath(dataset_dir)\n",
    "results_dir = os.path.abspath(results_dir)\n",
    "\n",
    "\n",
    "from VectorEmbeddingSearchingNick_v1 import VectorEmbeddingSearching as vesNick\n",
    "\n",
    "\n",
    "json_files =  ['MCQ_1hop.json', 'MCQ_2hop.json', 'OpenEnded_1hop.json', 'OpenEnded_2hop.json', 'True_or_False_1hop.json', 'True_or_False_2hop.json']\n",
    "\n",
    "responses = {}\n",
    "for json_file in json_files:\n",
    "    print(json_file)\n",
    "    with open(dataset_dir+'/'+json_file) as f:\n",
    "        data = json.load(f)\n",
    "    if \"True_or_False\" in json_file:\n",
    "        # Me\n",
    "        # for multiple choice questions\n",
    "        BASE_GENERATION_TEMPLATE = \"\"\"\n",
    "        {question} Please reply to the question with 'Answer: True' if the statement is correct, or 'Answer: False' if the statement is incorrect. Ensure you choose only one of these options.'\n",
    "        \"\"\"\n",
    "\n",
    "    elif \"MCQ\" in json_file:\n",
    "        # Me\n",
    "        # for multiple choice questions\n",
    "        BASE_GENERATION_TEMPLATE = \"\"\"\n",
    "        {question} Please respond in the format 'Answer:<number>'. For instance, if the correct answer to the question falls within choices 1 to 5 and the correct answer is 1, simply respond with 'Answer:1'\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Me\n",
    "        # for open ended questions\n",
    "        BASE_GENERATION_TEMPLATE = \"\"\"{question}\"\"\"\n",
    "\n",
    "    responses[json_file] = {}\n",
    "    for question in data:\n",
    "        response = ''\n",
    "        formatted_question = BASE_GENERATION_TEMPLATE.format(question = question['question'])\n",
    "        try:\n",
    "            \n",
    "            # Get the knowledge array\n",
    "            knowledge_array,distances = vesNick.get_knowledge(formatted_question,config_RAG_TEST=config_RAG_TEST)\n",
    "\n",
    "            print(\"Knowledge array:\",knowledge_array)\n",
    "\n",
    "            # get the answer using the knowledge array\n",
    "            response = vesNick.get_answer(question=formatted_question, knowledge_array=knowledge_array, config_RAG_TEST=config_RAG_TEST)\n",
    "            \n",
    "            # The reason why i commented out the following is because of this kind of response (Answer:1)\n",
    "            # For response= response[8:].strip(), the response is '', which is not what we want.\n",
    "            # Remove \"Answer:\" from the response\n",
    "            # if response.startswith(\"Answer:\"):\n",
    "            #     response= response[8:].strip()\n",
    "            \n",
    "            #remove ```cypher from the response\n",
    "            response = response.replace(\"```cypher\", \"\")\n",
    "\n",
    "            #remove ``` from anywhere in the response\n",
    "            response = response.replace(\"```\", \"\")\n",
    "\n",
    "            #remove \\n from the response\n",
    "            response = response.replace(\"\\n\", \"\")\n",
    "            \n",
    "            # print(\"Memgraph request:\",response)\n",
    "            print(\"question:\",question['question'])\n",
    "            print(\"request:\",response)\n",
    "        except Exception as e:\n",
    "            # print(\"Memgraph request failed\",e)\n",
    "            response = ''\n",
    "            print(\"error:\", e)\n",
    "        \n",
    "        responses[json_file][question['question']] = str(response)\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "dill.dump(responses, open(results_dir+'/'+'RAG_responses.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Assessing the score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = ['MCQ_1hop.json', 'MCQ_2hop.json', 'OpenEnded_1hop.json', 'OpenEnded_2hop.json', 'True_or_False_1hop.json', 'True_or_False_2hop.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_COMPARISON_TEMPLATE = \"\"\"\n",
    "Given this question: {question}\n",
    "And the ground truth answer: {ground_truth_answer}\n",
    "Determine if this answer by the student is correct. Give only a 1 for correct and 0 for incorrect: \n",
    "{answer}\n",
    "\"\"\"\n",
    "GET_ANSWER_MCQ_TEMPLATE = \"\"\"Given the following multiple choice question and options:\n",
    "{question}\n",
    "{options}\n",
    "\n",
    "And the student's answer:\n",
    "{answer}\n",
    "\n",
    "Which option did the student select?\"\"\"\n",
    "CONVERT_ANSWER_TO_ARRAY = \"\"\"Question:\n",
    "{question}\n",
    "Convert the following answer to a python array. return only the array as an evaluable string starting with [ and ending with ]:\n",
    "{answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the responses from the pickle files\n",
    "import dill\n",
    "base_responses = dill.load(open('../results/Base_responses.pkl', 'rb'))\n",
    "rag_responses = dill.load(open('../results/RAG_responses.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill \n",
    "import json\n",
    "files =  [\n",
    "    'MCQ_1hop.json',\n",
    "    'MCQ_2hop.json', \n",
    "    'OpenEnded_1hop.json', \n",
    "    'OpenEnded_2hop.json', \n",
    "    'True_or_False_1hop.json',\n",
    "    'True_or_False_2hop.json'\n",
    "]\n",
    "\n",
    "scores = {}\n",
    "response_from = ''\n",
    "score_data = {}\n",
    "\n",
    "#testing different responses. comment out the responses you don't want to test\n",
    "responses = dill.load(open(\"../results/Base_responses.pkl\", \"rb\"))\n",
    "response_from = 'base'\n",
    "\n",
    "# responses = dill.load(open(\"../results/RAG_responses.pkl\", \"rb\"))\n",
    "\n",
    "# responses = dill.load(open(\"Escargot_responses.pkl\", \"rb\"))\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    scores[file] = {}\n",
    "    score_data[file] = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    dataset = json.load(open(\"../dataset/\"+file, \"rb\"))\n",
    "\n",
    "    for question in dataset:\n",
    "        if \"MCQ\" in file or \"True_or_False\" in file:\n",
    "            if question['question'] not in responses[file]:\n",
    "                continue\n",
    "            total += 1\n",
    "            #compare the ground truth answer with the student's answer\n",
    "            response = responses[file][question['question']]\n",
    "            # print(response)\n",
    "            if \"MCQ\" in file:\n",
    "                options = question['question'].split('? ')[1]\n",
    "                formatted_answer_prompt = GET_ANSWER_MCQ_TEMPLATE.format(question=question['question'].split('? ')[0], options = options, answer = response)\n",
    "                formatted_answer = ''\n",
    "                try:\n",
    "                    formatted_answer = escargot.quick_chat(formatted_answer_prompt)\n",
    "                except Exception as e:\n",
    "                    print(\"LM request failed\",e)  \n",
    "                # print(formatted_answer)\n",
    "            else:\n",
    "                formatted_answer = response\n",
    "\n",
    "            formatted_question = GROUND_TRUTH_COMPARISON_TEMPLATE.format(question = question['question'], ground_truth_answer = question['answer'], answer = formatted_answer)\n",
    "            try:\n",
    "                score_response = escargot.quick_chat(formatted_question)\n",
    "            except Exception as e:\n",
    "                print(\"LM request failed\",e)\n",
    "            if \"1\" in score_response:\n",
    "                correct += 1\n",
    "                print(question['answer'], formatted_answer)\n",
    "            # elif len(score_response) != 1:\n",
    "            #     total -= 1\n",
    "            else:\n",
    "                print(question, response, formatted_answer, score_response)\n",
    "            score_data[file].append([question['question'], question['answer'], response, formatted_answer, score_response])\n",
    "            print(correct,'/', total, correct/total *100)\n",
    "        elif \"OpenEnded\" in file:\n",
    "            \n",
    "            total += 1\n",
    "            print(question['question'])\n",
    "            # if 'OpenEnded_1hop_Answers_ChatGPT_3.5_RAG', 'OpenEnded_2hop_Answers_ChatGPT_3.5_RAG\n",
    "            if 'OpenEnded_1hop_Answers_ChatGPT_3.5_RAG' in responses or response_from =='base':\n",
    "                if response_from != 'base':\n",
    "                    if file == 'OpenEnded_1hop.json':\n",
    "                        response = responses['OpenEnded_1hop_Answers_ChatGPT_3.5_RAG'][question['question']]\n",
    "                    elif file == 'OpenEnded_2hop.json':\n",
    "                        response = responses['OpenEnded_2hop_Answers_ChatGPT_3.5_RAG'][question['question']]\n",
    "                    array_answer = CONVERT_ANSWER_TO_ARRAY.format(question = question['question'], answer = response['response_by_llm'])\n",
    "                else:\n",
    "                    array_answer = CONVERT_ANSWER_TO_ARRAY.format(question = question['question'], answer = response)\n",
    "                # print(response['answer'])\n",
    "                \n",
    "                try:\n",
    "                    score_response = escargot.quick_chat(array_answer)\n",
    "                    # print(question, response, score_response)\n",
    "                except Exception as e:\n",
    "                    print(\"LM request failed\",e)\n",
    "                response = score_response\n",
    "                #lowercase\n",
    "                response = response.lower()\n",
    "            else:\n",
    "                response = responses[file][question['question']]\n",
    "                print(response)\n",
    "            #compare the ground truth answer with the student's answer\n",
    "            # response = responses[file][question['question']]\n",
    "            # question['answer']\n",
    "            \n",
    "\n",
    "            \n",
    "            try:\n",
    "                if total == 271:\n",
    "                    print(total)\n",
    "                if \"{'np'\" in response:\n",
    "                    #remove from 'np:' to the first > in the response\n",
    "                    response = '{' + response.split(\"'np':\")[1].split('>, ')[1]\n",
    "                    if \"array([\" in response:\n",
    "                        #remove from 'array([' to the first ']' in the response\n",
    "                        response = \"[\" + response.split(\"array([\")[1].split(']')[0] + \"]\"\n",
    "                try:\n",
    "                    response = eval(response)\n",
    "                except Exception as e:\n",
    "                    print(\"response eval prob:\",e)\n",
    "                    response = response.replace(\"nan\", \"None\")\n",
    "                # print(type(response))\n",
    "                #check if the response is a dict\n",
    "                if isinstance(response, dict):\n",
    "                    if len(response) > 0:\n",
    "                        response = response[list(response.keys())[-1]]\n",
    "                    else:\n",
    "                        response = []\n",
    "                if isinstance(response, set):\n",
    "                    response = list(response)\n",
    "                if isinstance(response, tuple):\n",
    "                    response = list(response[1])\n",
    "                #make sure the response is a list\n",
    "                if not isinstance(response, list):\n",
    "                    response = [response]\n",
    "                \n",
    "                if len(response) == 1:\n",
    "                    if \"[\" in response[0]:\n",
    "                        response = response[0].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "                        response = response.split(',')\n",
    "                        response = [answer.strip() for answer in response]\n",
    "                        #remove ' from the response\n",
    "                        response = [answer.replace(\"'\", \"\") for answer in response]\n",
    "                        response = [answer.replace('\"', \"\") for answer in response]\n",
    "                    #if there is Alzheimer's Disease in the response, there may be a comma afterwards describing a specific type of Alzheimer's Disease\n",
    "                    # such as if response = \"Alzheimer's Disease, Focal Onset, Alzheimer's Disease, Early-Onset, Alzheimer's Disease, Late-Onset\"\n",
    "                    # we want this to look like the array ['alzheimer's disease, focal onset', 'alzheimer's disease, early-onset', 'alzheimer's disease, late-onset']\n",
    "                    if \"Alzheimer's Disease\" in response[0]:\n",
    "                        response = response\n",
    "                    if \",\" in response[0] and \"Alzheimer's Disease\" not in response[0]:\n",
    "                        response = response[0].split(',')\n",
    "                        response = [answer.strip() for answer in response]\n",
    "\n",
    "                #if \"biological-region\" is in the array\n",
    "                if \"biological-region\" in response:\n",
    "                    response = [answer.replace(\"biological-region\", \"biological-region gene\") for answer in response]\n",
    "                    #protein-coding\n",
    "                if \"protein-coding\" in response:\n",
    "                    response = [answer.replace(\"protein-coding\", \"protein-coding gene\") for answer in response]\n",
    "                if \"ncRNA\" in response:\n",
    "                    response = [answer.replace(\"ncRNA\", \"ncRNA gene\") for answer in response]\n",
    "                response = [answer.lower() for answer in response]\n",
    "                print(response)\n",
    "                if \"Alzheimer Disease, Late Onset\" in question['answer'] or \"Alzheimer Disease, Early Onset\" in question['answer'] or \"Alzheimer's Disease, Focal Onset\" in question['answer']:\n",
    "                    gt_array = []\n",
    "                    if \"Alzheimer Disease, Late Onset\" in question['answer']:\n",
    "                        gt_array.append(\"Alzheimer Disease, Late Onset\")\n",
    "                        #remove the Alzheimer Disease, Late Onset from the question['answer']\n",
    "                        question['answer'] = question['answer'].replace(\"Alzheimer Disease, Late Onset\", \"\")\n",
    "                    if \"Alzheimer Disease, Early Onset\" in question['answer']:\n",
    "                        gt_array.append(\"Alzheimer Disease, Early Onset\")\n",
    "                        #remove the Alzheimer Disease, Early Onset from the question['answer']\n",
    "                        question['answer'] = question['answer'].replace(\"Alzheimer Disease, Early Onset\", \"\")\n",
    "                    if \"Alzheimer's Disease, Focal Onset\" in question['answer']:\n",
    "                        gt_array.append(\"Alzheimer's Disease, Focal Onset\")\n",
    "                        #remove the Alzheimer Disease, Focal Onset from the question['answer']\n",
    "                        question['answer'] = question['answer'].replace(\"Alzheimer's Disease, Focal Onset\", \"\")\n",
    "                    gt_answer = question['answer'].lower().split(',')\n",
    "                    #append the gt_array to the gt_answer\n",
    "                    gt_answer = gt_answer + gt_array\n",
    "                else:\n",
    "                    gt_answer = question['answer'].lower().split(',')\n",
    "                gt_answer = [answer.strip() for answer in gt_answer]\n",
    "                # remove empty strings from the list\n",
    "                gt_answer = [answer.lower() for answer in gt_answer if answer != '']\n",
    "                print(gt_answer)\n",
    "\n",
    "                #metric only for the OpenEnded questions\n",
    "                count_of_intersection = len(set(response).intersection(set(gt_answer)))\n",
    "                unique_union = len(set(response).union(set(gt_answer)))\n",
    "                if len(response) > len(gt_answer):\n",
    "                    score = count_of_intersection/(unique_union + 5*(unique_union - count_of_intersection))\n",
    "                else:\n",
    "                    score = count_of_intersection/unique_union\n",
    "                if score < 0.6:\n",
    "                    print(\"question:\", question['question'])\n",
    "                    # print(\"original response:\", responses[file][question['question']])\n",
    "                    print(\"response:\", response)\n",
    "                    print(\"ground truth:\", gt_answer)\n",
    "                    print(\"score:\", score)\n",
    "                    print(\"\\n\")\n",
    "                print(\"score:\", score)\n",
    "                print(\"\\n\")\n",
    "                correct += score\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"response eval prob:\",e)\n",
    "                break\n",
    "\n",
    "            print(correct,'/', total, correct/total *100)\n",
    "        \n",
    "    scores[file][\"correct\"] = correct\n",
    "    scores[file][\"total\"] = total\n",
    "    scores[file][\"percentage\"] = correct/total *100\n",
    "    print('dataset_total:', len(dataset), 'correct:', correct, 'total:', total, 'percentage:', correct/total *100)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-alzkb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
